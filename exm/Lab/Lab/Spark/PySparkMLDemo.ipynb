{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/spark2.4.3\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/local/anaconda/bin/python\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/local/anaconda/bin/python\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark import SparkContext, SparkConf\n",
    "#conf = SparkConf().setAppName(\"appName\")\n",
    "#sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"PySpark ML Demo\").enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.3\n"
     ]
    }
   ],
   "source": [
    "# What version of Spark?\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contain 50000 records.\n"
     ]
    }
   ],
   "source": [
    "# Load some airline flight data from a CSV file 'flights.csv'\n",
    "# The file needs to be uploaded from your local machine to Jupyter Notebook in advance\n",
    "\n",
    "# In the dataset, fields are separated by a comma and missing data are denoted by the string 'NA'.\n",
    "\n",
    "# Data dictionary:\n",
    "# mon — month (integer between 1 and 12)\n",
    "# dom — day of month (integer between 1 and 31)\n",
    "# dow — day of week (integer; 1 = Monday and 7 = Sunday)\n",
    "# org — origin airport (IATA code)\n",
    "# mile — distance (miles)\n",
    "# carrier — carrier (IATA code)\n",
    "# depart — departure time (decimal hour)\n",
    "# duration — expected duration (minutes)\n",
    "# delay — delay (minutes)\n",
    "\n",
    "# Read the flights dataset\n",
    "# inferSchema: Infer data types of columns automatically\n",
    "# nullValue: Deal with missing data\n",
    "\n",
    "flights_original = spark.read.csv('flights.csv',sep=',',header=True,inferSchema=True,nullValue='NA')\n",
    "# Get number of records. The count() method gives the number of records.\n",
    "print(\"The data contain %d records.\" % flights_original.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351| null|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8|\n",
      "|  9| 13|  1|     AA|   419|ORD|1236| 10.33|     195|   -5|\n",
      "|  4|  2|  5|     AA|   325|ORD| 258|  8.92|      65| null|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the first five records. The show() method displays the first few records.\n",
    "flights_original.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mon', 'int'), ('dom', 'int'), ('dow', 'int'), ('carrier', 'string'), ('flight', 'int'), ('org', 'string'), ('mile', 'int'), ('depart', 'double'), ('duration', 'int'), ('delay', 'int')]\n"
     ]
    }
   ],
   "source": [
    "# Check column data types. The dtypes attribute gives the column types\n",
    "print(flights_original.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sms.csv dataset contains a selection of SMS messages which have been classified as\n",
    "# either 'spam' (1) or 'ham' (0)\n",
    "# Notes on CSV format:\n",
    "# no header record and\n",
    "# fields are separated by a semicolon (this is not the default separator of ',')\n",
    "# Data dictionary:\n",
    "# id — record identifier\n",
    "# text — content of SMS message\n",
    "# label — spam or ham (integer; 0 = ham and 1 = spam)\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "# Specify column names and types\n",
    "# Specify the data schema, giving columns names (\"id\", \"text\", and \"label\") and column types.\n",
    "myschema = StructType([\n",
    "StructField(\"id\", IntegerType()),  \n",
    "StructField(\"text\", StringType()),\n",
    "StructField(\"label\", IntegerType())\n",
    "])\n",
    "# Load data from a delimited file\n",
    "sms_original = spark.read.csv(\"sms.csv\", sep=';', header=False, schema=myschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print schema of DataFrame\n",
    "sms_original.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to develop a model which will predict whether or not a given flight will be delayed.\n",
    "# Firstly we need to trim those data down by:\n",
    "# - removing an uninformative column and\n",
    "# - removing rows which do not have information about whether or not a flight was delayed.\n",
    "# Remove the 'flight' column which is irrelevant for prediction\n",
    "# The drop() method applies to columns only.\n",
    "flights_drop_column = flights_original.drop('flight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2978"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of records with missing 'delay' values\n",
    "# Use the filter() method to choose specific rows and\n",
    "# the count() method to find the number of rows in the result.\n",
    "flights_drop_column.filter('delay IS NULL').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove records with missing 'delay' values\n",
    "flights_valid_delay = flights_drop_column.filter('delay IS NOT NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records without any missing values:  47022\n"
     ]
    }
   ],
   "source": [
    "# Remove records with missing values in any column and get the number of remaining rows\n",
    "# The dropna() method will discard all records with any missing fields.\n",
    "flights_none_missing = flights_valid_delay.dropna()\n",
    "print(\"Number of records without any missing values: \", flights_none_missing.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step of preparing the flight data has two parts:\n",
    "# - convert the units of distance, replacing the mile column with a kmcolumn; and\n",
    "# - create a Boolean column indicating whether or not a flight was delayed.\n",
    "# Import the required function\n",
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'mile' to 'km' and drop 'mile' column\n",
    "# Use the withColumn() method to manipulate columns.\n",
    "flights_adding_km = flights_none_missing.withColumn('km', round(flights_original.mile * 1.60934, 0)).drop('mile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'label' column indicating whether flight delayed (1) or not (0)\n",
    "# a flight to be \"delayed\" when it arrives 15 minutes or more after its scheduled time.\n",
    "flights_adding_km = flights_adding_km.withColumn('label', (flights_adding_km.delay >= 15).cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 509.0|    1|\n",
      "|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 542.0|    0|\n",
      "|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1989.0|    0|\n",
      "|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 885.0|    0|\n",
      "|  7|  2|  6|     AA|ORD| 10.83|     135|   54|1180.0|    1|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check first five records\n",
    "flights_adding_km.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the flights data there are two columns, carrier and org, which hold categorical data.\n",
    "# You need to transform those columns into indexed numerical values.\n",
    "# Machine Learning model needs numbers not strings, so these transformations are vital!\n",
    "# Import the appropriate class and create an indexer object to\n",
    "# transform the carrier column from a string to an numeric index\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an indexer; Prepare the indexer object on the flight data.\n",
    "indexer = StringIndexer(inputCol='carrier', outputCol='carrier_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexer identifies categories in the data\n",
    "indexer_model = indexer.fit(flights_adding_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexer creates a new column with numeric index values\n",
    "flights_indexed = indexer_model.transform(flights_adding_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the process for the other categorical feature\n",
    "flights_indexed = StringIndexer(inputCol='org', outputCol='org_idx').fit(flights_indexed).transform(flights_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 509.0|    1|        0.0|    0.0|\n",
      "|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 542.0|    0|        0.0|    1.0|\n",
      "|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1989.0|    0|        1.0|    0.0|\n",
      "|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 885.0|    0|        0.0|    1.0|\n",
      "|  7|  2|  6|     AA|ORD| 10.83|     135|   54|1180.0|    1|        1.0|    0.0|\n",
      "|  1| 16|  6|     UA|ORD|   8.0|     232|   -7|2317.0|    0|        0.0|    0.0|\n",
      "|  1| 22|  5|     UA|SJC|  7.98|     250|  -13|2943.0|    0|        0.0|    5.0|\n",
      "| 11|  8|  1|     OO|SFO|  7.77|      60|   88| 254.0|    1|        2.0|    1.0|\n",
      "|  4| 26|  1|     AA|SFO| 13.25|     210|  -10|2356.0|    0|        1.0|    1.0|\n",
      "|  4| 25|  0|     AA|ORD| 13.75|     160|   31|1574.0|    1|        1.0|    0.0|\n",
      "|  8| 30|  2|     UA|ORD| 13.28|     151|   16|1157.0|    1|        0.0|    0.0|\n",
      "|  3| 16|  3|     UA|ORD|   9.0|     264|    3|2808.0|    0|        0.0|    0.0|\n",
      "|  0|  3|  4|     AA|LGA| 17.08|     190|   32|1765.0|    1|        1.0|    3.0|\n",
      "|  5|  9|  1|     UA|SFO|  12.7|     158|   20|1556.0|    1|        0.0|    1.0|\n",
      "|  3| 10|  4|     B6|ORD| 17.58|     265|  155|2792.0|    1|        4.0|    0.0|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "only showing top 15 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(flights_indexed.show(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final stage of data preparation is to consolidate all of the predictor columns into a single column.\n",
    "# An updated version of the flights data, which takes into account all of the changes,\n",
    "# has the following predictor columns:\n",
    "# - mon, dom and dow\n",
    "# - carrier_idx (indexed value from carrier)\n",
    "# - org_idx (indexed value from org)\n",
    "# - km\n",
    "# - depart\n",
    "# - duration\n",
    "\n",
    "# Import the class which will assemble the predictors.\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assembler object that can merge the predictors columns into a single column.\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "'mon', 'dom', 'dow', 'carrier_idx', 'org_idx', 'km', 'depart', 'duration'\n",
    "], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate predictor columns\n",
    "flights_assembled = assembler.transform(flights_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----+\n",
      "|features                                 |delay|\n",
      "+-----------------------------------------+-----+\n",
      "|[0.0,22.0,2.0,0.0,0.0,509.0,16.33,82.0]  |30   |\n",
      "|[2.0,20.0,4.0,0.0,1.0,542.0,6.17,82.0]   |-8   |\n",
      "|[9.0,13.0,1.0,1.0,0.0,1989.0,10.33,195.0]|-5   |\n",
      "|[5.0,2.0,1.0,0.0,1.0,885.0,7.98,102.0]   |2    |\n",
      "|[7.0,2.0,6.0,1.0,0.0,1180.0,10.83,135.0] |54   |\n",
      "+-----------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the resulting column\n",
    "flights_assembled.select('features', 'delay').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|            features|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 509.0|    1|        0.0|    0.0|[0.0,22.0,2.0,0.0...|\n",
      "|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 542.0|    0|        0.0|    1.0|[2.0,20.0,4.0,0.0...|\n",
      "|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1989.0|    0|        1.0|    0.0|[9.0,13.0,1.0,1.0...|\n",
      "|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 885.0|    0|        0.0|    1.0|[5.0,2.0,1.0,0.0,...|\n",
      "|  7|  2|  6|     AA|ORD| 10.83|     135|   54|1180.0|    1|        1.0|    0.0|[7.0,2.0,6.0,1.0,...|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_assembled.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|            features|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "|  0|  1|  2|     AA|JFK|  6.58|     230|   50|2570.0|    1|        1.0|    2.0|[0.0,1.0,2.0,1.0,...|\n",
      "|  0|  1|  2|     AA|JFK|   7.0|     385|  -16|4162.0|    0|        1.0|    2.0|[0.0,1.0,2.0,1.0,...|\n",
      "|  0|  1|  2|     AA|JFK|  12.0|     370|   11|3983.0|    0|        1.0|    2.0|[0.0,1.0,2.0,1.0,...|\n",
      "|  0|  1|  2|     AA|JFK|  17.0|     379|  -10|3983.0|    0|        1.0|    2.0|[0.0,1.0,2.0,1.0,...|\n",
      "|  0|  1|  2|     AA|LGA|  8.25|     250|   27|2235.0|    1|        1.0|    3.0|[0.0,1.0,2.0,1.0,...|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# We will split the data into two components:\n",
    "# - training data (used to train the model) and\n",
    "# - testing data (used to test the model).\n",
    "# Split into training and testing sets in a 80:20 ratio\n",
    "flights_train, flights_test = flights_assembled.randomSplit([0.8, 0.2], seed=17)\n",
    "print(flights_train.show(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980732423121092\n"
     ]
    }
   ],
   "source": [
    "# Check that training set has around 80% of records\n",
    "training_ratio = flights_train.count() / flights_assembled.count()\n",
    "print(training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------------------------------------+\n",
      "|label|prediction|probability                            |\n",
      "+-----+----------+---------------------------------------+\n",
      "|1    |1.0       |[0.4931950745301361,0.5068049254698639]|\n",
      "|1    |1.0       |[0.35528564453125,0.64471435546875]    |\n",
      "|1    |1.0       |[0.35528564453125,0.64471435546875]    |\n",
      "|1    |1.0       |[0.35528564453125,0.64471435546875]    |\n",
      "|1    |1.0       |[0.35528564453125,0.64471435546875]    |\n",
      "+-----+----------+---------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the Decision Tree Classifier class\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Create a classifier object and fit to the training data\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_model = tree.fit(flights_train)\n",
    "\n",
    "# Create predictions for the testing data and take a look at the predictions\n",
    "prediction = tree_model.transform(flights_test)\n",
    "prediction.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 1201|\n",
      "|    0|       0.0| 2411|\n",
      "|    1|       1.0| 3623|\n",
      "|    0|       1.0| 2260|\n",
      "+-----+----------+-----+\n",
      "\n",
      "0.635492364402317\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the decision tree using confusion matrix\n",
    "# A confusion matrix gives a useful breakdown of predictions versus known values.\n",
    "# It has four cells which represent the counts of:\n",
    "# - True Negatives (TN): model predicts negative outcome & known outcome is negative\n",
    "# - True Positives (TP): model predicts positive outcome & known outcome is positive\n",
    "# - False Negatives (FN): model predicts negative outcome but known outcome is positive\n",
    "# - False Positives (FP): model predicts positive outcome but known outcome is negative.\n",
    "# Create a confusion matrix by counting the combinations of label and prediction. Display the result.\n",
    "prediction.groupBy('label', 'prediction').count().show()\n",
    "# Count # of True Negatives, True Positives, False Negatives and False Positives in confusion matrix\n",
    "# Use the predicatea:\n",
    "# - prediction = 0 AND label = prediction (TF)\n",
    "# - prediction = 1 AND label = prediction (TP)\n",
    "# - prediction = 0 AND label != prediction (FN)\n",
    "# - prediction = 1 AND label != prediction (FP)\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "# Accuracy measures the proportion of correct predictions\n",
    "# The accuracy is the ratio of correct predictions (TP and TN) to all predictions (TP, TN, FP and FN)\n",
    "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|            features|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "|  0|  1|  2|     AA|JFK|  6.58|     230|   50|2570.0|    1|        1.0|    2.0|[0.0,1.0,2.0,1.0,...|\n",
      "|  0|  1|  2|     AA|JFK|   7.0|     385|  -16|4162.0|    0|        1.0|    2.0|[0.0,1.0,2.0,1.0,...|\n",
      "|  0|  1|  2|     AA|JFK|  12.0|     370|   11|3983.0|    0|        1.0|    2.0|[0.0,1.0,2.0,1.0,...|\n",
      "|  0|  1|  2|     AA|JFK|  17.0|     379|  -10|3983.0|    0|        1.0|    2.0|[0.0,1.0,2.0,1.0,...|\n",
      "|  0|  1|  2|     AA|LGA|  8.25|     250|   27|2235.0|    1|        1.0|    3.0|[0.0,1.0,2.0,1.0,...|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### Use logistic regression to predict whether a flight is likely to be delayed by\n",
    "# at least 15 minutes (label 1) or not (label 0).\n",
    "# Import the logistic regression class\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "# Create a classifier object and train on training data\n",
    "logistic = LogisticRegression().fit(flights_train)\n",
    "\n",
    "print(flights_train.show(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 1652|\n",
      "|    0|       0.0| 2645|\n",
      "|    1|       1.0| 3172|\n",
      "|    0|       1.0| 2026|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create predictions for the testing data and show confusion matrix\n",
    "prediction = logistic.transform(flights_test)\n",
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.62\n",
      "recall = 0.75\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the logistic regression model.\n",
    "# Accuracy is generally not a very reliable metric because it can be biased by the most common target class\n",
    "# There are two other useful metrics:\n",
    "# - Precision is the proportion of positive predictions which are correct, ie. TP/(TP+FP)\n",
    "# - Recall is the proportion of positives outcomes which are correctly predicted, ie. TP/(TP+FN)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "# Calculate precision and recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print('precision = {:.2f}\\nrecall = {:.2f}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6501216177018289\n"
     ]
    }
   ],
   "source": [
    "# Find weighted precision.\n",
    "# The weighted precision indicates what proportion of predictions (positive and negative) are correct.\n",
    "# Create a multi-class evaluator and evaluate weighted precision.\n",
    "# The metric name is \"weightedPrecision\".\n",
    "multi_evaluator = MulticlassClassificationEvaluator()\n",
    "weighted_precision = multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
    "# Find AUC\n",
    "# Create a binary evaluator and evaluate AUC using the \"areaUnderROC\" metric.\n",
    "binary_evaluator = BinaryClassificationEvaluator()\n",
    "auc = binary_evaluator.evaluate(prediction, {binary_evaluator.metricName: \"areaUnderROC\"})\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------+-----+------------------------------------------+\n",
      "|id |text                              |label|words                                     |\n",
      "+---+----------------------------------+-----+------------------------------------------+\n",
      "|1  |Sorry I'll call later in meeting  |0    |[sorry, i'll, call, later, in, meeting]   |\n",
      "|2  |Dont worry I guess he's busy      |0    |[dont, worry, i, guess, he's, busy]       |\n",
      "|3  |Call FREEPHONE now                |1    |[call, freephone, now]                    |\n",
      "|4  |Win a cash prize or a prize worth |1    |[win, a, cash, prize, or, a, prize, worth]|\n",
      "+---+----------------------------------+-----+------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Another example of classification using logistic regression for the sms dataset\n",
    "# Firstly to repare the SMS messages as follows:\n",
    "# - remove punctuation and numbers\n",
    "# - tokenize (split into individual words)\n",
    "# - remove stop words\n",
    "# - apply the hashing trick\n",
    "# - convert to TF-IDF representation.\n",
    "# Import the necessary functions\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "# Use regular expressions (or REGEX) to remove the punctuation symbols.\n",
    "# Replace all punctuation characters from the text column with a space.\n",
    "# Do the same for all numbers in the text column.\n",
    "wrangled = sms_original.withColumn('text', regexp_replace(sms_original.text, '[_():;,.!?\\\\-]', ' '))\n",
    "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, '[0-9]', ' '))\n",
    "# Merge multiple spaces\n",
    "sms_cleaned = wrangled.withColumn('text', regexp_replace(wrangled.text, ' +', ' '))\n",
    "# Split the text into words\n",
    "# Split the 'text' column into tokens. Name the output column 'words'\n",
    "sms_tokenized = Tokenizer(inputCol='text', outputCol='words').transform(sms_cleaned)\n",
    "sms_tokenized.show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 1230|\n",
      "|    0|       0.0| 2465|\n",
      "|    1|       1.0| 3594|\n",
      "|    0|       1.0| 2206|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the decision tree using confusion matrix\n",
    "# A confusion matrix gives a useful breakdown of predictions versus known values.\n",
    "# It has four cells which represent the counts of:\n",
    "# - True Negatives (TN): model predicts negative outcome & known outcome is negative\n",
    "# - True Positives (TP): model predicts positive outcome & known outcome is positive\n",
    "# - False Negatives (FN): model predicts negative outcome but known outcome is positive\n",
    "# - False Positives (FP): model predicts positive outcome but known outcome is negative.\n",
    "# Create a confusion matrix by counting the combinations of label and prediction. Display the result.\n",
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6381253291205898\n"
     ]
    }
   ],
   "source": [
    "# Count # of True Negatives, True Positives, False Negatives and False Positives in confusion matrix\n",
    "# Use the predicatea:\n",
    "# - prediction = 0 AND label = prediction (TF)\n",
    "# - prediction = 1 AND label = prediction (TP)\n",
    "# - prediction = 0 AND label != prediction (FN)\n",
    "# - prediction = 1 AND label != prediction (FP)\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "# Accuracy measures the proportion of correct predictions\n",
    "# The accuracy is the ratio of correct predictions (TP and TN) to all predictions (TP, TN, FP and FN)\n",
    "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover, HashingTF, IDF\n",
    "# Remove stop words - to eliminate so commonly used words that carry very little useful info.\n",
    "# StopWordsRemover class contains a list of stop words which can be customized if necessary.\n",
    "sms_without_stop = StopWordsRemover(inputCol='words', outputCol='terms').transform(sms_tokenized)\n",
    "# Apply the hashing trick\n",
    "# The hashing trick provides a fast and space-efficient way to\n",
    "# map a very large (possibly infinite) set of items (in this case, all words contained in the SMS messages)\n",
    "# onto a smaller, finite number of values.\n",
    "sms_hashed = HashingTF(inputCol='terms', outputCol='hash', numFeatures=1024).transform(sms_without_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|terms                           |features                                                                                            |\n",
      "+--------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|[sorry, call, later, meeting]   |(1024,[138,344,378,1006],[2.2391682769656747,2.892706319430574,3.684405173719015,4.244020961654438])|\n",
      "|[dont, worry, guess, busy]      |(1024,[53,233,329,858],[4.618714411095849,3.557143394108088,4.618714411095849,4.937168142214383])   |\n",
      "|[call, freephone]               |(1024,[138,396],[2.2391682769656747,3.3843005812686773])                                            |\n",
      "|[win, cash, prize, prize, worth]|(1024,[31,69,387,428],[3.7897656893768414,7.284881949239966,4.4671645129686475,3.898659777615979])  |\n",
      "+--------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert hashed symbols to TF-IDF representation\n",
    "# The TF-IDF matrix reflects how important a word is to each document.\n",
    "# It takes into account both the frequency of the word within each document but also\n",
    "# the frequency of the word across all of the documents in the collection.\n",
    "# ie. Weight the number of counts for a word in a particular document against\n",
    "# how frequently that word occurs across all documents\n",
    "sms_tfidf = IDF(inputCol='hash', outputCol='features').fit(sms_hashed).transform(sms_hashed)\n",
    "sms_tfidf.select('terms', 'features').show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|   47|\n",
      "|    0|       0.0|  987|\n",
      "|    1|       1.0|  124|\n",
      "|    0|       1.0|    3|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the tf_idf data into training and testing sets in a 4:1 ratio\n",
    "sms_train, sms_test = sms_tfidf.randomSplit([0.8, 0.2], seed=13)\n",
    "# Fit a Logistic Regression model to the training data\n",
    "logistic = LogisticRegression(regParam=0.2).fit(sms_train)\n",
    "# Make predictions on the testing data\n",
    "prediction = logistic.transform(sms_test)\n",
    "# Create a confusion matrix, comparing predictions to known labels\n",
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
